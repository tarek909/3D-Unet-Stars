{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0GLezhHtyaT",
        "outputId": "0e0cb623-3a59-4020-c744-742361a48d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '3D-Unet-Stars'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 76 (delta 8), reused 76 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone  https://github.com/tarek909/3D-Unet-Stars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGOgn1_Ht2ya",
        "outputId": "2c2a5c05-d515-4fc0-bae7-94a7228f3b82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting monai\n",
            "  Downloading monai-1.0.1-202210241233-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from monai) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from monai) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->monai) (4.1.1)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/gdrive/MyDrive/LITSS/example'\n",
        "import sys\n",
        "import os\n",
        "py_file_location = \"/content/3D-Unet-Stars/pytorch3dunet/datasets\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "import loader_18_nov"
      ],
      "metadata": {
        "id": "HdnHedF-t4qu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset_path, 2, num_workers=0, pin_memory=False, test_size=0.0, transform=True, keys=(\"image\", \"label\"), size=[512, 512, 400])\n",
        "training_ds = loader.get_training_data();\n",
        "for t in training_ds:\n",
        "   batch_size = len(t['image'])\n",
        "   for j in range(batch_size):\n",
        "    print(np.shape(t['image'][j]))\n",
        "    print(np.shape(t['image'][j]))\n",
        "    print('___end of batch___')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "_U-rkMthwskG",
        "outputId": "adafa77a-4604-49ba-f8d0-37d1370440a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "volume path: /content/gdrive/MyDrive/LITSS/example/volume/Copy of volume-11.nii mask path: /content/gdrive/MyDrive/LITSS/example/mask/Copy of segmentation-11.nii\n",
            "/content/gdrive/MyDrive/LITSS/example/volume/Copy of volume-11.nii /content/gdrive/MyDrive/LITSS/example/mask/Copy of segmentation-11.nii\n",
            "volume path: /content/gdrive/MyDrive/LITSS/example/volume/Copy of volume-13.nii mask path: /content/gdrive/MyDrive/LITSS/example/mask/Copy of segmentation-13.nii\n",
            "/content/gdrive/MyDrive/LITSS/example/volume/Copy of volume-13.nii /content/gdrive/MyDrive/LITSS/example/mask/Copy of segmentation-13.nii\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7465838161f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_18_nov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m    \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/3D-Unet-Stars/pytorch3dunet/datasets/loader_18_nov.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/3D-Unet-Stars/pytorch3dunet/datasets/loader_18_nov.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_transform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmap_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# if in debug mode, don't swallow exception so that the breakpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/transform.py\u001b[0m in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/intensity/dictionary.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/intensity/array.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0msub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtrahend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtrahend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                     \u001b[0mdiv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivisor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivisor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m                 )\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/intensity/array.py\u001b[0m in \u001b[0;36m_normalize\u001b[0;34m(self, img, sub, div)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0m_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0m_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_div\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/transforms/intensity/array.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/data/meta_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;31m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# if \"out\" in kwargs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "py_file_location1 = \"/content/3D-Unet-Stars/pytorch3dunet\"\n",
        "sys.path.append(os.path.abspath(py_file_location1))\n",
        "import yaml\n",
        "with open('/content/3D-Unet-Stars/resources/3DUnet_denoising/train_config_regression.yaml','r') as file:\n",
        "    config = yaml.safe_load(file)\n"
      ],
      "metadata": {
        "id": "sCDvQ6q2zlV3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qaFwQBH22m5",
        "outputId": "aee5a5af-12eb-40bc-9482-eb93197b6f8d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model': {'name': 'UNet3D', 'in_channels': 1, 'out_channels': 1, 'layer_order': 'gcr', 'f_maps': [16, 32, 64, 128, 256], 'num_groups': 8, 'is_segmentation': False}, 'trainer': {'checkpoint_dir': 'CHECKPOINT_DIR', 'resume': None, 'pre_trained': None, 'validate_after_iters': 1000, 'log_after_iters': 100, 'max_num_epochs': 1000, 'max_num_iterations': 100000, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 1e-05}, 'loss': {'name': 'SmoothL1Loss', 'ignore_index': None}, 'eval_metric': {'name': 'PSNR', 'ignore_index': None}, 'lr_scheduler': {'name': 'ReduceLROnPlateau', 'mode': 'max', 'factor': 0.1, 'patience': 10}, 'loaders': {'dataset': 'StandardHDF5Dataset', 'batch_size': 1, 'num_workers': 4, 'raw_internal_path': 'raw', 'label_internal_path': 'random', 'weight_internal_path': None, 'train': {'file_paths': ['PATH_TO_TRAIN_SET'], 'slice_builder': {'name': 'SliceBuilder', 'patch_shape': [128, 128, 128], 'stride_shape': [32, 32, 32]}, 'transformer': {'raw': [{'name': 'Normalize'}, {'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 30, 'mode': 'reflect'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'Normalize'}, {'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 30, 'mode': 'reflect'}, {'name': 'ToTensor', 'expand_dims': True}]}}, 'val': {'file_paths': ['PATH_TO_VAL_SET'], 'slice_builder': {'name': 'SliceBuilder', 'patch_shape': [128, 128, 128], 'stride_shape': [128, 128, 128]}, 'transformer': {'raw': [{'name': 'Normalize'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'Normalize'}, {'name': 'ToTensor', 'expand_dims': True}]}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from pytorch3dunet.datasets.utils import get_train_loaders\n",
        "from pytorch3dunet.unet3d.losses import get_loss_criterion\n",
        "from pytorch3dunet.unet3d.metrics import get_evaluation_metric\n",
        "from pytorch3dunet.unet3d.model import get_model\n",
        "from pytorch3dunet.unet3d.utils import get_logger, get_tensorboard_formatter, create_optimizer, \\\n",
        "    create_lr_scheduler, get_number_of_learnable_parameters\n",
        "from . import utils\n",
        "\n",
        "logger = get_logger('UNet3DTrainer')\n",
        "\n",
        "\n",
        "def create_trainer(config):\n",
        "    # Create the model\n",
        "    model = get_model(config['model'])\n",
        "    # use DataParallel if more than 1 GPU available\n",
        "    device = config['device']\n",
        "    if torch.cuda.device_count() > 1 and not device.type == 'cpu':\n",
        "        model = nn.DataParallel(model)\n",
        "        logger.info(f'Using {torch.cuda.device_count()} GPUs for training')\n",
        "\n",
        "    # put the model on GPUs\n",
        "    logger.info(f\"Sending the model to '{config['device']}'\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Log the number of learnable parameters\n",
        "    logger.info(f'Number of learnable params {get_number_of_learnable_parameters(model)}')\n",
        "\n",
        "    # Create loss criterion\n",
        "    loss_criterion = get_loss_criterion(config)\n",
        "    # Create evaluation metric\n",
        "    eval_criterion = get_evaluation_metric(config)\n",
        "\n",
        "    # Create data loaders\n",
        "    loaders = get_train_loaders(config)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = create_optimizer(config['optimizer'], model)\n",
        "\n",
        "    # Create learning rate adjustment strategy\n",
        "    lr_scheduler = create_lr_scheduler(config.get('lr_scheduler', None), optimizer)\n",
        "\n",
        "    trainer_config = config['trainer']\n",
        "    # Create tensorboard formatter\n",
        "    tensorboard_formatter = get_tensorboard_formatter(trainer_config.pop('tensorboard_formatter', None))\n",
        "    # Create trainer\n",
        "    resume = trainer_config.pop('resume', None)\n",
        "    pre_trained = trainer_config.pop('pre_trained', None)\n",
        "\n",
        "    return UNet3DTrainer(model=model,\n",
        "                         optimizer=optimizer,\n",
        "                         lr_scheduler=lr_scheduler,\n",
        "                         loss_criterion=loss_criterion,\n",
        "                         eval_criterion=eval_criterion,\n",
        "                         tensorboard_formatter=tensorboard_formatter,\n",
        "                         device=config['device'],\n",
        "                         loaders=loaders,\n",
        "                         resume=resume,\n",
        "                         pre_trained=pre_trained,\n",
        "                         **trainer_config)\n",
        "\n",
        "\n",
        "class UNet3DTrainer:\n",
        "    \"\"\"3D UNet trainer.\n",
        "\n",
        "    Args:\n",
        "        model (Unet3D): UNet 3D model to be trained\n",
        "        optimizer (nn.optim.Optimizer): optimizer used for training\n",
        "        lr_scheduler (torch.optim.lr_scheduler._LRScheduler): learning rate scheduler\n",
        "            WARN: bear in mind that lr_scheduler.step() is invoked after every validation step\n",
        "            (i.e. validate_after_iters) not after every epoch. So e.g. if one uses StepLR with step_size=30\n",
        "            the learning rate will be adjusted after every 30 * validate_after_iters iterations.\n",
        "        loss_criterion (callable): loss function\n",
        "        eval_criterion (callable): used to compute training/validation metric (such as Dice, IoU, AP or Rand score)\n",
        "            saving the best checkpoint is based on the result of this function on the validation set\n",
        "        device (torch.device): device to train on\n",
        "        loaders (dict): 'train' and 'val' loaders\n",
        "        checkpoint_dir (string): dir for saving checkpoints and tensorboard logs\n",
        "        max_num_epochs (int): maximum number of epochs\n",
        "        max_num_iterations (int): maximum number of iterations\n",
        "        validate_after_iters (int): validate after that many iterations\n",
        "        log_after_iters (int): number of iterations before logging to tensorboard\n",
        "        validate_iters (int): number of validation iterations, if None validate\n",
        "            on the whole validation set\n",
        "        eval_score_higher_is_better (bool): if True higher eval scores are considered better\n",
        "        best_eval_score (float): best validation score so far (higher better)\n",
        "        num_iterations (int): useful when loading the model from the checkpoint\n",
        "        num_epoch (int): useful when loading the model from the checkpoint\n",
        "        tensorboard_formatter (callable): converts a given batch of input/output/target image to a series of images\n",
        "            that can be displayed in tensorboard\n",
        "        skip_train_validation (bool): if True eval_criterion is not evaluated on the training set (used mostly when\n",
        "            evaluation is expensive)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, optimizer, lr_scheduler, loss_criterion,\n",
        "                 eval_criterion, device, loaders, checkpoint_dir,\n",
        "                 max_num_epochs, max_num_iterations,\n",
        "                 validate_after_iters=200, log_after_iters=100,\n",
        "                 validate_iters=None, num_iterations=1, num_epoch=0,\n",
        "                 eval_score_higher_is_better=True,\n",
        "                 tensorboard_formatter=None, skip_train_validation=False,\n",
        "                 resume=None, pre_trained=None, **kwargs):\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = lr_scheduler\n",
        "        self.loss_criterion = loss_criterion\n",
        "        self.eval_criterion = eval_criterion\n",
        "        self.device = device\n",
        "        self.loaders = loaders\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.max_num_epochs = max_num_epochs\n",
        "        self.max_num_iterations = max_num_iterations\n",
        "        self.validate_after_iters = validate_after_iters\n",
        "        self.log_after_iters = log_after_iters\n",
        "        self.validate_iters = validate_iters\n",
        "        self.eval_score_higher_is_better = eval_score_higher_is_better\n",
        "\n",
        "        logger.info(model)\n",
        "        logger.info(f'eval_score_higher_is_better: {eval_score_higher_is_better}')\n",
        "\n",
        "        # initialize the best_eval_score\n",
        "        if eval_score_higher_is_better:\n",
        "            self.best_eval_score = float('-inf')\n",
        "        else:\n",
        "            self.best_eval_score = float('+inf')\n",
        "\n",
        "\n",
        "        assert tensorboard_formatter is not None, 'TensorboardFormatter must be provided'\n",
        "        self.tensorboard_formatter = tensorboard_formatter\n",
        "\n",
        "        self.num_iterations = num_iterations\n",
        "        self.num_epochs = num_epoch\n",
        "        self.skip_train_validation = skip_train_validation\n",
        "\n",
        "        if resume is not None:\n",
        "            logger.info(f\"Loading checkpoint '{resume}'...\")\n",
        "            state = utils.load_checkpoint(resume, self.model, self.optimizer)\n",
        "            logger.info(\n",
        "                f\"Checkpoint loaded from '{resume}'. Epoch: {state['num_epochs']}.  Iteration: {state['num_iterations']}. \"\n",
        "                f\"Best val score: {state['best_eval_score']}.\"\n",
        "            )\n",
        "            self.best_eval_score = state['best_eval_score']\n",
        "            self.num_iterations = state['num_iterations']\n",
        "            self.num_epochs = state['num_epochs']\n",
        "            self.checkpoint_dir = os.path.split(resume)[0]\n",
        "        elif pre_trained is not None:\n",
        "            logger.info(f\"Logging pre-trained model from '{pre_trained}'...\")\n",
        "            utils.load_checkpoint(pre_trained, self.model, None)\n",
        "            if 'checkpoint_dir' not in kwargs:\n",
        "                self.checkpoint_dir = os.path.split(pre_trained)[0]\n",
        "\n",
        "    def fit(self):\n",
        "        for _ in range(self.num_epochs, self.max_num_epochs):\n",
        "            # train for one epoch\n",
        "            should_terminate = self.train()\n",
        "\n",
        "            if should_terminate:\n",
        "                logger.info('Stopping criterion is satisfied. Finishing training')\n",
        "                return\n",
        "\n",
        "            self.num_epochs += 1\n",
        "        logger.info(f\"Reached maximum number of epochs: {self.max_num_epochs}. Finishing training...\")\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Trains the model for 1 epoch.\n",
        "\n",
        "        Returns:\n",
        "            True if the training should be terminated immediately, False otherwise\n",
        "        \"\"\"\n",
        "        train_losses = utils.RunningAverage()\n",
        "        train_eval_scores = utils.RunningAverage()\n",
        "\n",
        "        # sets the model in training mode\n",
        "        self.model.train()\n",
        "\n",
        "        for t in self.loaders['train']:\n",
        "            logger.info(f'Training iteration [{self.num_iterations}/{self.max_num_iterations}]. '\n",
        "                        f'Epoch [{self.num_epochs}/{self.max_num_epochs - 1}]')\n",
        "\n",
        "            input, target, weight = self._split_training_batch(t)\n",
        "\n",
        "            output, loss = self._forward_pass(input, target, weight)\n",
        "\n",
        "            train_losses.update(loss.item(), self._batch_size(input))\n",
        "\n",
        "            # compute gradients and update parameters\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if self.num_iterations % self.validate_after_iters == 0:\n",
        "                # set the model in eval mode\n",
        "                self.model.eval()\n",
        "                # evaluate on validation set\n",
        "                eval_score = self.validate()\n",
        "                # set the model back to training mode\n",
        "                self.model.train()\n",
        "\n",
        "                # adjust learning rate if necessary\n",
        "                if isinstance(self.scheduler, ReduceLROnPlateau):\n",
        "                    self.scheduler.step(eval_score)\n",
        "                else:\n",
        "                    self.scheduler.step()\n",
        "                # log current learning rate in tensorboard\n",
        "                self._log_lr()\n",
        "                # remember best validation metric\n",
        "                is_best = self._is_best_eval_score(eval_score)\n",
        "\n",
        "                # save checkpoint\n",
        "                self._save_checkpoint(is_best)\n",
        "\n",
        "            if self.num_iterations % self.log_after_iters == 0:\n",
        "                # compute eval criterion\n",
        "                if not self.skip_train_validation:\n",
        "                    eval_score = self.eval_criterion(output, target)\n",
        "                    train_eval_scores.update(eval_score.item(), self._batch_size(input))\n",
        "\n",
        "                # log stats, params and images\n",
        "                logger.info(\n",
        "                    f'Training stats. Loss: {train_losses.avg}. Evaluation score: {train_eval_scores.avg}')\n",
        "                self._log_stats('train', train_losses.avg, train_eval_scores.avg)\n",
        "                self._log_params()\n",
        "                self._log_images(input, target, output, 'train_')\n",
        "\n",
        "            if self.should_stop():\n",
        "                return True\n",
        "\n",
        "            self.num_iterations += 1\n",
        "\n",
        "        return False\n",
        "\n",
        "    def should_stop(self):\n",
        "        \"\"\"\n",
        "        Training will terminate if maximum number of iterations is exceeded or the learning rate drops below\n",
        "        some predefined threshold (1e-6 in our case)\n",
        "        \"\"\"\n",
        "        if self.max_num_iterations < self.num_iterations:\n",
        "            logger.info(f'Maximum number of iterations {self.max_num_iterations} exceeded.')\n",
        "            return True\n",
        "\n",
        "        min_lr = 1e-6\n",
        "        lr = self.optimizer.param_groups[0]['lr']\n",
        "        if lr < min_lr:\n",
        "            logger.info(f'Learning rate below the minimum {min_lr}.')\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def validate(self):\n",
        "        logger.info('Validating...')\n",
        "\n",
        "        val_losses = utils.RunningAverage()\n",
        "        val_scores = utils.RunningAverage()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, t in enumerate(self.loaders['val']):\n",
        "                logger.info(f'Validation iteration {i}')\n",
        "\n",
        "                input, target, weight = self._split_training_batch(t)\n",
        "\n",
        "                output, loss = self._forward_pass(input, target, weight)\n",
        "                val_losses.update(loss.item(), self._batch_size(input))\n",
        "\n",
        "                if i % 100 == 0:\n",
        "                    self._log_images(input, target, output, 'val_')\n",
        "\n",
        "                eval_score = self.eval_criterion(output, target)\n",
        "                val_scores.update(eval_score.item(), self._batch_size(input))\n",
        "\n",
        "                if self.validate_iters is not None and self.validate_iters <= i:\n",
        "                    # stop validation\n",
        "                    break\n",
        "\n",
        "            self._log_stats('val', val_losses.avg, val_scores.avg)\n",
        "            logger.info(f'Validation finished. Loss: {val_losses.avg}. Evaluation score: {val_scores.avg}')\n",
        "            return val_scores.avg\n",
        "\n",
        "    def _split_training_batch(self, t):\n",
        "        def _move_to_device(input):\n",
        "            if isinstance(input, tuple) or isinstance(input, list):\n",
        "                return tuple([_move_to_device(x) for x in input])\n",
        "            else:\n",
        "                return input.to(self.device)\n",
        "\n",
        "        t = _move_to_device(t)\n",
        "        weight = None\n",
        "        if len(t) == 2:\n",
        "            input, target = t\n",
        "        else:\n",
        "            input, target, weight = t\n",
        "        return input, target, weight\n",
        "\n",
        "    def _forward_pass(self, input, target, weight=None):\n",
        "        # forward pass\n",
        "        output = self.model(input)\n",
        "\n",
        "        # compute the loss\n",
        "        if weight is None:\n",
        "            loss = self.loss_criterion(output, target)\n",
        "        else:\n",
        "            loss = self.loss_criterion(output, target, weight)\n",
        "\n",
        "        return output, loss\n",
        "\n",
        "    def _is_best_eval_score(self, eval_score):\n",
        "        if self.eval_score_higher_is_better:\n",
        "            is_best = eval_score > self.best_eval_score\n",
        "        else:\n",
        "            is_best = eval_score < self.best_eval_score\n",
        "\n",
        "        if is_best:\n",
        "            logger.info(f'Saving new best evaluation metric: {eval_score}')\n",
        "            self.best_eval_score = eval_score\n",
        "\n",
        "        return is_best\n",
        "\n",
        "    def _save_checkpoint(self, is_best):\n",
        "        # remove `module` prefix from layer names when using `nn.DataParallel`\n",
        "        # see: https://discuss.pytorch.org/t/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict/1686/20\n",
        "        if isinstance(self.model, nn.DataParallel):\n",
        "            state_dict = self.model.module.state_dict()\n",
        "        else:\n",
        "            state_dict = self.model.state_dict()\n",
        "\n",
        "        last_file_path = os.path.join(self.checkpoint_dir, 'last_checkpoint.pytorch')\n",
        "        logger.info(f\"Saving checkpoint to '{last_file_path}'\")\n",
        "\n",
        "        utils.save_checkpoint({\n",
        "            'num_epochs': self.num_epochs + 1,\n",
        "            'num_iterations': self.num_iterations,\n",
        "            'model_state_dict': state_dict,\n",
        "            'best_eval_score': self.best_eval_score,\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "        }, is_best, checkpoint_dir=self.checkpoint_dir)\n",
        "\n",
        "    def _log_lr(self):\n",
        "        lr = self.optimizer.param_groups[0]['lr']\n",
        "        self.writer.add_scalar('learning_rate', lr, self.num_iterations)\n",
        "\n",
        "    def _log_stats(self, phase, loss_avg, eval_score_avg):\n",
        "        tag_value = {\n",
        "            f'{phase}_loss_avg': loss_avg,\n",
        "            f'{phase}_eval_score_avg': eval_score_avg\n",
        "        }\n",
        "\n",
        "        for tag, value in tag_value.items():\n",
        "            self.writer.add_scalar(tag, value, self.num_iterations)\n",
        "\n",
        "    def _log_params(self):\n",
        "        logger.info('Logging model parameters and gradients')\n",
        "        for name, value in self.model.named_parameters():\n",
        "            self.writer.add_histogram(name, value.data.cpu().numpy(), self.num_iterations)\n",
        "            self.writer.add_histogram(name + '/grad', value.grad.data.cpu().numpy(), self.num_iterations)\n",
        "\n",
        "    def _log_images(self, input, target, prediction, prefix=''):\n",
        "        if self.model.training:\n",
        "            if isinstance(self.model, nn.DataParallel):\n",
        "                net = self.model.module\n",
        "            else:\n",
        "                net = self.model\n",
        "\n",
        "            if net.final_activation is not None:\n",
        "                prediction = net.final_activation(prediction)\n",
        "\n",
        "        inputs_map = {\n",
        "            'inputs': input,\n",
        "            'targets': target,\n",
        "            'predictions': prediction\n",
        "        }\n",
        "        img_sources = {}\n",
        "        for name, batch in inputs_map.items():\n",
        "            if isinstance(batch, list) or isinstance(batch, tuple):\n",
        "                for i, b in enumerate(batch):\n",
        "                    img_sources[f'{name}{i}'] = b.data.cpu().numpy()\n",
        "            else:\n",
        "                img_sources[name] = batch.data.cpu().numpy()\n",
        "\n",
        "        for name, batch in img_sources.items():\n",
        "            for tag, image in self.tensorboard_formatter(name, batch):\n",
        "                self.writer.add_image(prefix + tag, image, self.num_iterations)\n",
        "\n",
        "    @staticmethod\n",
        "    def _batch_size(input):\n",
        "        if isinstance(input, list) or isinstance(input, tuple):\n",
        "            return input[0].size(0)\n",
        "        else:\n",
        "            return input.size(0)\n"
      ],
      "metadata": {
        "id": "trg233BVw1u9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}